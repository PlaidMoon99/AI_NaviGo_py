from fastapi import FastAPI, HTTPException
import pymysql
import pandas as pd
from rapidfuzz import fuzz
import unicodedata
import os
import math  # NaN ê²€ì‚¬ìš©

app = FastAPI(docs_url="/docs", openapi_url="/openapi.json")

EXCEL_FILE_PATH = "data/í•œêµ­ê´€ê´‘ê³µì‚¬_êµ­ë¬¸_ì„œë¹„ìŠ¤ë¶„ë¥˜ì½”ë“œ_v4.2_gs.xlsx"
category_data_cache = None

def get_connection():
    return pymysql.connect(
        host="192.168.0.6",
        user="sion",
        password="00000000",
        database="navi_go",
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor
    )

async def get_user_preference(member_id):
    connection = get_connection()
    cursor = connection.cursor()
    sql = "SELECT prefer_purpose FROM preference WHERE member_id = %s"
    cursor.execute(sql, (member_id,))
    result = cursor.fetchone()
    connection.close()
    return result["prefer_purpose"] if result else None

async def get_user_click_history(member_id):
    connection = get_connection()
    cursor = connection.cursor()
    # ì‹¤ì œ í…Œì´ë¸”ì—ì„œëŠ” 'clicked_at' ì»¬ëŸ¼ìœ¼ë¡œ ë˜ì–´ ìˆìŒ
    sql = "SELECT contentid, cat1, cat2, cat3, clicked_at FROM user_activity WHERE memberid = %s"
    cursor.execute(sql, (member_id,))
    result = cursor.fetchall()
    connection.close()
    return result

def load_category_data():
    global category_data_cache
    if category_data_cache is not None:
        return category_data_cache
    if not os.path.exists(EXCEL_FILE_PATH):
        raise FileNotFoundError(f"âŒ ì—‘ì…€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {EXCEL_FILE_PATH}")
    print("ğŸ”„ ì—‘ì…€ íŒŒì¼ ë¡œë”© ì¤‘...")
    try:
        xls = pd.ExcelFile(EXCEL_FILE_PATH, engine="openpyxl")
        available_sheets = xls.sheet_names
        sheet_name = "ì‹œíŠ¸1" if "ì‹œíŠ¸1" in available_sheets else available_sheets[0]
        df = pd.read_excel(xls, sheet_name=sheet_name, dtype=str)
        expected_columns = ["contenttypeid", "cat1", "cat2", "cat3", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]
        df.columns = expected_columns[:len(df.columns)]
        df = df.dropna(how="all").reset_index(drop=True)
        df["ì†Œë¶„ë¥˜"] = df["ì†Œë¶„ë¥˜"].astype(str).str.strip()
        print("âœ… [ì—‘ì…€ ë¡œë”© ì™„ë£Œ] ë°ì´í„° ê°œìˆ˜:", df.shape[0])
        category_data_cache = df
        return df
    except Exception as e:
        raise Exception(f"âŒ ì—‘ì…€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def deep_normalize(text: str) -> str:
    if not text:
        return ""
    text = unicodedata.normalize('NFC', text)
    for ch in ["\u00A0", "\u200B", "\u2006", "\u202F"]:
        text = text.replace(ch, "")
    return ''.join(text.split())

def sanitize_rec(rec: dict) -> dict:
    # NaN (float('nan')) ê²€ì‚¬ë¥¼ í†µí•´ NaNì¸ ê°’ì€ Noneìœ¼ë¡œ ì¹˜í™˜
    for k, v in rec.items():
        if isinstance(v, float) and math.isnan(v):
            rec[k] = None
    return rec

def fallback_recommendation(category_data, norm_user_pref):
    data_copy = category_data.copy()
    data_copy["ì†Œë¶„ë¥˜_norm"] = data_copy["ì†Œë¶„ë¥˜"].apply(lambda x: deep_normalize(x))
    data_copy["similarity"] = data_copy["ì†Œë¶„ë¥˜_norm"].apply(lambda x: fuzz.ratio(norm_user_pref, x) if norm_user_pref else 0)
    print("\nğŸ” [Fallback Matching] ê²°ê³¼:")
    print(data_copy[["cat3", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "similarity"]])
    if not data_copy.empty:
        best_idx = data_copy["similarity"].idxmax()
        best_match = data_copy.loc[best_idx]
        if best_match["similarity"] >= 60:
            rec = {
                "cat3": best_match["cat3"],
                "ëŒ€ë¶„ë¥˜": best_match["ëŒ€ë¶„ë¥˜"],
                "ì¤‘ë¶„ë¥˜": best_match["ì¤‘ë¶„ë¥˜"],
                "ì†Œë¶„ë¥˜": best_match["ì†Œë¶„ë¥˜"],
                "similarity": float(best_match["similarity"])
            }
            rec = sanitize_rec(rec)
            print(f"ğŸŸ£ Fallback ì¶”ì²œ ê²°ê³¼: {rec}")
            return rec
    fallback = category_data.sample(n=min(3, len(category_data)))[["cat3", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]].to_dict(orient="records")
    rec = fallback[0] if fallback else None
    rec = sanitize_rec(rec) if rec else None
    print(f"ğŸŸ£ ìµœì¢… ë¬´ì‘ìœ„ fallback ì¶”ì²œ: {rec}")
    return rec

# ì¶”ì²œ ë¡œì§: í´ë¦­ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ, í´ë¦­ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìµœì‹  3ê±´ì„ ê¸°ì¤€ìœ¼ë¡œ
# ë¹ˆë„ìˆ˜ ê¸°ë°˜ í›„ë³´ë¥¼ ì„ ì •í•˜ê³ , ë¹ˆë„ tie ì‹œì—ë§Œ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ í™œìš©í•˜ì—¬ tie-break
async def recommend_best_cat3(member_id):
    print(f"\n\nâœ… ì¶”ì²œ ìš”ì²­ëœ member_id: {member_id}")
    user_clicks = await get_user_click_history(member_id)
    user_preference = await get_user_preference(member_id)
    print(f"ğŸŸ¢ user_preference (ì†Œë¶„ë¥˜ ì„ í˜¸): {user_preference}")

    category_data = load_category_data()
    norm_user_pref = deep_normalize(user_preference) if user_preference else None
    print(f"ğŸ” ì •ê·œí™”ëœ ì‚¬ìš©ì ì„ í˜¸ë„: {norm_user_pref}")

    import pandas as pd
    # í´ë¦­ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì„ í˜¸ë„ ê¸°ë°˜ fallback ì¶”ì²œ ì‚¬ìš©
    if not user_clicks:
        print("í´ë¦­ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ ì§„í–‰")
        return fallback_recommendation(category_data, norm_user_pref)

    # í´ë¦­ ë°ì´í„°ê°€ ìˆì„ ë•Œ: ìµœì‹  3ê±´ ì¶”ì¶œ (clicked_at ê¸°ì¤€)
    clicks_df = pd.DataFrame(user_clicks)
    if "clicked_at" in clicks_df.columns:
        clicks_df["clicked_at"] = pd.to_datetime(clicks_df["clicked_at"])
        clicks_df = clicks_df.sort_values(by="clicked_at", ascending=False)
        latest_clicks = clicks_df.head(3)
    else:
        latest_clicks = clicks_df

    if latest_clicks.empty:
        return fallback_recommendation(category_data, norm_user_pref)

    # Step 1: ìµœì‹  í´ë¦­ ê¸°ë¡ì—ì„œ cat3 ë¹ˆë„ìˆ˜ ê³„ì‚°
    freq = latest_clicks["cat3"].value_counts()
    print("í´ë¦­ ê¸°ë¡ ë¹ˆë„ìˆ˜:\n", freq)
    if freq.empty:
        return fallback_recommendation(category_data, norm_user_pref)
    
    # ë¹ˆë„ìˆ˜ê°€ ìœ ì¼í•˜ë©´ ê·¸ í›„ë³´ ì‚¬ìš©
    if len(freq) == 1:
        selected_candidate = freq.index[0]
        print(f"ìœ ì¼í•œ í›„ë³´: {selected_candidate}")
    else:
        max_freq = freq.max()
        candidate_list = freq[freq == max_freq].index.tolist()
        print(f"ë¹ˆë„ tie í›„ë³´ë“¤: {candidate_list}")
        # Tie-break: í›„ë³´ ëª©ë¡ ì¤‘, tie ìƒí™©ì—ì„œëŠ” ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ì¼ì¹˜í•˜ëŠ” í›„ë³´ ìš°ì„ 
        if len(candidate_list) > 1:
            category_data["ì†Œë¶„ë¥˜_norm"] = category_data["ì†Œë¶„ë¥˜"].apply(lambda x: deep_normalize(x))
            category_data["pref_similarity"] = category_data["ì†Œë¶„ë¥˜_norm"].apply(lambda x: fuzz.ratio(norm_user_pref, x) if norm_user_pref else 0)
            best_idx_pref = category_data["pref_similarity"].idxmax()
            preferred_cat3 = category_data.loc[best_idx_pref, "cat3"]
            print(f"ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ cat3: {preferred_cat3}")
            if preferred_cat3 in candidate_list:
                selected_candidate = preferred_cat3
                print(f"ì„ í˜¸ë„ ê¸°ë°˜ í›„ë³´ {preferred_cat3} ì„ íƒ (tie-break)")
            else:
                # tie í›„ë³´ë“¤ ì¤‘ ì¶”ê°€ ê¸°ì¤€ ì—†ì´ í›„ë³´ë³„ ì†Œë¶„ë¥˜ ìœ ì‚¬ë„ ìµœëŒ€ê°’ì„ ë¹„êµí•˜ì—¬ ì„ íƒ
                candidate_scores = {}
                for candidate in candidate_list:
                    candidate_df = category_data[category_data["cat3"] == candidate].copy()
                    candidate_df["ì†Œë¶„ë¥˜_norm"] = candidate_df["ì†Œë¶„ë¥˜"].apply(lambda x: deep_normalize(x))
                    candidate_scores[candidate] = candidate_df["ì†Œë¶„ë¥˜_norm"].apply(lambda x: fuzz.ratio(norm_user_pref, x)).max() if not candidate_df.empty else 0
                    print(f"Candidate {candidate} ìœ ì‚¬ë„: {candidate_scores[candidate]}")
                selected_candidate = max(candidate_scores, key=candidate_scores.get)
                print(f"ìµœì¢… tie-break í›„ë³´: {selected_candidate}")
        else:
            selected_candidate = candidate_list[0]
            print(f"ìœ ì¼ í›„ë³´ ì„ íƒ: {selected_candidate}")

    # Step 2: ì„ íƒëœ í›„ë³´ì— í•´ë‹¹í•˜ëŠ” Excel ë°ì´í„°ì—ì„œ í•´ë‹¹ cat3 ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì¶”ì²œ
    candidate_df = category_data[category_data["cat3"] == selected_candidate].copy()
    if not candidate_df.empty:
        rec = candidate_df.iloc[0].to_dict()
        rec["source"] = "click ê¸°ë°˜ ì¶”ì²œ"
        rec = sanitize_rec(rec)
        print(f"ğŸŸ£ ìµœì¢… ì¶”ì²œ ê²°ê³¼ (í´ë¦­ ë°ì´í„° ê¸°ë°˜): {rec}")
        return rec

    return fallback_recommendation(category_data, norm_user_pref)

@app.get("/recommend/{member_id}")
async def get_recommendations(member_id: str):
    recommendation = await recommend_best_cat3(member_id)
    if not recommendation:
        raise HTTPException(status_code=404, detail="No recommendations found")
    return recommendation

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=5000, reload=True)